# ONNX OCR Flutter Plugin - Development Context

## Project Overview

### Intention

Create a Flutter plugin (initially Android-only) that performs Optical Character Recognition (OCR) on images using ONNX models. The plugin should:

- Take an image as input and return detected text
- Display selectable text overlay on top of images (similar to iOS apps)
- Be easily integrable into existing Flutter applications
- Process everything on-device for privacy and performance

### Implementation Strategy

The plugin is a **direct port** of the [OnnxOCR Python implementation](https://github.com/jingsongliujing/OnnxOCR) (cloned in `./OnnxOCR/`) to Android/Kotlin, maintaining exact compatibility with:

- The same ONNX models (PaddleOCR v5)
- The same preprocessing/postprocessing logic
- The same detection, classification, and recognition pipeline

### Critical Constraints

‚ö†Ô∏è **NO OPENCV OR LARGE SDKS** ‚ö†Ô∏è

**This plugin MUST NOT use OpenCV or any other large SDK/library that bundles native .so files.**

The only exception is ONNX Runtime, which is allowed and needed.

**Reasoning:**

- OpenCV for Android adds 10-20 MB of native libraries (.so files) for multiple architectures
- This creates unacceptable bloat for the host application
- The plugin should remain lightweight and dependency-minimal

**Allowed Approaches:**

1. **Native Android APIs only** (Bitmap, Canvas, Matrix, Paint, etc.)
2. **Pure Kotlin/Java code** without native dependencies
3. **Custom implementations** of algorithms when needed
4. **Lightweight pure-code packages** that have no .so files or large SDK dependencies

**Forbidden Approaches:**

- ‚ùå OpenCV (cv2, org.opencv)
- ‚ùå Any library that bundles native .so files
- ‚ùå Large image processing SDKs

**When porting Python code that uses cv2:**

- Use Android's Bitmap and Canvas APIs for image operations
- Implement custom algorithms in Kotlin where necessary
- Accept that some operations may differ slightly from Python's cv2 implementation, as long as the end accuracy is still good.

## Current Architecture

### Project Structure

```
onnx_ocr_plugin/
‚îú‚îÄ‚îÄ android/                    # Android native implementation
‚îÇ   ‚îî‚îÄ‚îÄ src/main/kotlin/
‚îÇ       ‚îú‚îÄ‚îÄ OnnxOcrPlugin.kt   # Main plugin class (Flutter interface)
‚îÇ       ‚îú‚îÄ‚îÄ OcrProcessor.kt     # OCR pipeline orchestrator
‚îÇ       ‚îú‚îÄ‚îÄ TextDetector.kt     # Text detection (DB algorithm)
‚îÇ       ‚îú‚îÄ‚îÄ TextRecognizer.kt   # Text recognition (CTC decoder)
‚îÇ       ‚îú‚îÄ‚îÄ TextClassifier.kt   # Angle classification
‚îÇ       ‚îî‚îÄ‚îÄ ImageUtils.kt       # Image processing utilities
‚îú‚îÄ‚îÄ lib/                        # Flutter/Dart interface
‚îÇ   ‚îú‚îÄ‚îÄ onnx_ocr_plugin.dart   # Main plugin API
‚îÇ   ‚îî‚îÄ‚îÄ onnx_ocr_plugin_platform_interface.dart
‚îú‚îÄ‚îÄ assets/models/              # ONNX models from PaddleOCR v5
‚îÇ   ‚îú‚îÄ‚îÄ det/det.onnx           # Detection model (~4.75 MB)
‚îÇ   ‚îú‚îÄ‚îÄ rec/rec.onnx           # Recognition model (~16.5 MB)
‚îÇ   ‚îú‚îÄ‚îÄ cls/cls.onnx           # Classification model (~583 KB)
‚îÇ   ‚îî‚îÄ‚îÄ ppocrv5_dict.txt       # Character dictionary
‚îî‚îÄ‚îÄ example/                    # Sample app demonstrating usage
```

### OCR Pipeline (Exact Copy of OnnxOCR)

1. **Text Detection** (`TextDetector.kt`)

   - Algorithm: DB (Differentiable Binarization)
   - Input preprocessing:
     - Resize image with `limit_side_len=960` (min side)
     - Make dimensions multiple of 32
     - Normalize with mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
     - Scale: 1/255
     - Convert to CHW format
   - Output postprocessing:
     - Threshold: 0.3 (binarization)
     - Box threshold: 0.6 (minimum score)
     - Unclip ratio: 1.5 (box expansion)
     - Min size: 3x3 pixels

2. **Text Angle Classification** (`TextClassifier.kt`)

   - Purpose: Detect 180-degree rotated text
   - Input shape: (3, 48, 192)
   - Normalization: (pixel/255 - 0.5) / 0.5
   - Threshold: 0.9 for rotation decision
   - Classes: ["0", "180"]

3. **Text Recognition** (`TextRecognizer.kt`)
   - Algorithm: SVTR_LCNet with CTC decoder
   - Input shape: (3, 48, 320)
   - Batch processing: 6 images at once
   - Normalization: (pixel/255 - 0.5) / 0.5
   - CTC decoding with blank token removal
   - Character dictionary: ppocrv5_dict.txt (Chinese + English)

### Key Implementation Details

#### Native Layer (Kotlin)

- **ONNX Runtime**: Version 1.16.3 for Android (only allowed external dependency)
- **Async Processing**: Kotlin coroutines for non-blocking operations
- **Memory Optimization**: All heavy processing stays in native layer
- **No OpenCV**: All image processing uses native Android APIs (Bitmap, Canvas, Matrix, Paint) or custom Kotlin implementations
- **Zero .so file bloat**: No native libraries beyond ONNX Runtime
- **Batch Processing**: Recognition processes up to 6 regions simultaneously

#### Flutter Layer

- **Method Channel**: Communication with native code
- **Data Models**:
  - `OcrResult`: Contains boxes, texts, and confidence scores
  - `TextBox`: Four corner points defining text region
  - `TextResult`: Combined box + text + score
- **Image Support**: Accepts Uint8List (PNG/JPEG format)

#### Sample App Features

- Image selection from camera/gallery
- Text detection with visual overlay
- Tap-to-select text regions
- Selectable text display in dialogs
- View all detected text in a list
- Copy individual or all text to clipboard
- Confidence-based color coding (green/orange/red)

### Model Parameters (From OnnxOCR Analysis)

#### Detection Model

- **Preprocessing**: DetResizeForTest ‚Üí NormalizeImage ‚Üí ToCHWImage
- **Postprocessing**: DBPostProcess with polygon/quad output
- **Key parameters**:
  - `det_limit_side_len`: 960
  - `det_db_thresh`: 0.3
  - `det_db_box_thresh`: 0.6
  - `det_db_unclip_ratio`: 1.5

#### Recognition Model

- **Image dimensions**: 48 height, 320 max width
- **Character set**: ~6000+ Chinese characters + English + symbols
- **Decoding**: CTC with blank token at index 0
- **Confidence**: Average of character probabilities

## Current Issues

### 1. **Spaces Not Detected** ‚úÖ FIXED

- **Problem**: Spaces between words are missing in recognized text
- **Root Cause**: Character dictionary was not appending space character after loading from file
- **Solution**: Updated `OcrProcessor.loadCharacterDict()` to match Python implementation by appending " " before prepending "blank" token
- **Fixed in**: OcrProcessor.kt:57-65

### 2. **Text Recognition Accuracy** üî¥

- **Problem**: Character recognition errors on simple, readable text. Example: "Me randomly when I love you" ‚Üí "Me randomly when lve vou"
- **Goal**: Should achieve 100% accuracy on the test sentence "Me randomly when I love you" as it's clearly readable and uses common characters
- **Current Issues**:
  - Character confusion: "I" ‚Üí "l", "o" ‚Üí "v", "y" ‚Üí "v"
  - Truncation partially fixed (unclip operation added), but recognition accuracy still not matching Python implementation
- **Fixed So Far**:
  - ‚úÖ Added unclip/expand operation (1.5x) to TextDetector - significantly improved edge truncation
  - ‚úÖ Fixed crop dimension calculation to use max of opposing sides in ImageUtils.kt
  - ‚úÖ "Nobody:" now recognized perfectly (99.8%)
  - ‚úÖ "BeamCardShop" now complete (was "BeamCardShor")
  - ‚úÖ "randomly" now correct (was "randomlv")
- **Remaining Issues**:
  - Text cropping may still differ from Python (perspective transform, interpolation, borderMode)
  - Recognition preprocessing may have subtle differences
  - Need to compare cropped text regions with Python output

### 3. **App Crashes on Large Images** üî¥

- **Problem**: Sample app crashes with medium/large images
- **Symptoms**: Likely OutOfMemoryError
- **Likely Causes**:
  - No image downscaling before processing
  - Bitmap operations creating multiple copies in memory
  - ONNX session memory not being released properly
  - Need to implement image size limits or progressive downscaling

### 4. **OCR consistently failing on certain images** üî¥

- **Problem**: Sample app gives an error when processing certain images
- **Symptoms**: PlatformException(OCR_ERROR, Failed to process image: Index 3 out of bounds for length 2, null, null)

## Next Steps / TODOs

### High Priority Fixes

1. **Fix Text Recognition Accuracy** (CRITICAL - Must achieve 100% on test sentence)

   - [x] Debug space character handling in CTC decoder ‚úÖ
   - [x] Verify character dictionary is loaded correctly ‚úÖ
   - [x] Add unclip operation to expand text regions before cropping ‚úÖ
   - [x] Fix crop dimension calculation to use max of opposing sides ‚úÖ
   - [ ] Compare cropped text regions with Python implementation output
   - [ ] Verify perspective transform matches Python (borderMode: BORDER_REPLICATE, interpolation: INTER_CUBIC)
   - [ ] Check if recognition preprocessing exactly matches Python
   - [ ] Debug why "I love you" ‚Üí "lve vou" (should be perfect match)
   - **Success Criteria**: "Me randomly when I love you" recognized with 100% accuracy

2. **Fix Memory Issues**

   - [ ] Add image size validation and automatic downscaling
   - [ ] Implement memory-efficient bitmap handling
   - [ ] Add proper cleanup of ONNX tensors after inference
   - [ ] Consider processing in tiles for very large images

3. **Fix Index Out of Bounds Error**
   - [ ] Debug "Index 3 out of bounds for length 2" error on certain images
   - [ ] Add proper bounds checking and error handling

### Feature Enhancements

1. **Performance Optimization**

   - [ ] Profile and optimize preprocessing operations
   - [ ] Implement caching for repeated OCR on same image
   - [ ] Add progress callbacks for long operations

2. **Language Support**

   - [ ] Make character dictionary configurable
   - [ ] Add English-only mode for smaller model size
   - [ ] Support for additional languages

3. **iOS Support**

   - [ ] Implement iOS native code (Swift/Objective-C)
   - [ ] Ensure feature parity with Android

4. **Advanced Features**
   - [ ] Add text region editing/correction
   - [ ] Implement paragraph detection and reading order
   - [ ] Add export formats (PDF, structured text)

### Code Quality

1. **Error Handling**

   - [ ] Add comprehensive error messages
   - [ ] Implement fallback mechanisms
   - [ ] Add logging for debugging

2. **Testing**

   - [ ] Unit tests for image processing functions
   - [ ] Integration tests for OCR pipeline
   - [ ] Performance benchmarks

3. **Documentation**
   - [ ] API documentation
   - [ ] Integration guide
   - [ ] Troubleshooting guide

## Technical Debt

1. **Contour Detection**: Current implementation is simplified

   - Need proper connected component analysis
   - Should use more sophisticated contour tracing

2. **Minimum Area Rectangle**: Using bounding box instead of proper min area rect

   - Need to implement rotating calipers algorithm

3. **Polygon Expansion**: Basic implementation of unclip operation
   - Should use proper Clipper library for polygon operations

## Configuration Notes

### Android Build Configuration

```gradle
dependencies {
    implementation("com.microsoft.onnxruntime:onnxruntime-android:1.16.3")
    implementation("org.jetbrains.kotlinx:kotlinx-coroutines-android:1.7.3')
   }
```

### Required Permissions (Android)

```xml
<uses-permission android:name="android.permission.CAMERA" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
```

## Testing & Verification Workflow

### Quick Testing via Sample App

The example app is configured for easy testing and verification of OCR functionality:

#### Running Tests

**For Developers:**

```bash
cd example/
flutter run
```

**For AI Agents:**

‚ö†Ô∏è **CRITICAL: ALWAYS use Task tool with general-purpose agent** ‚ö†Ô∏è

NEVER run `flutter run` directly with Bash tool - it produces massive console output that ruins context.

Use the Task tool with the general-purpose subagent to:

1. Run `flutter run` in the example directory
2. Monitor the console output for OCR results
3. Report back only the key findings (detected text vs ground truth)
4. Do NOT include full logs in the context (to prevent overload)

#### What Happens Automatically

1. **Auto-load First Test Image** (3 second delay)

   - App loads `meme_love_you.jpeg` on startup
   - Waits 3 seconds for ONNX models to initialize
   - Automatically runs OCR

2. **Console Output Format**

   ```
   ========================================
   Loaded test image: meme_love_you.jpeg
   ========================================

   ‚è≥ Waiting 3 seconds for models to initialize...

   ========== OCR RESULTS ==========
   Total regions detected: 3

   Recognized texts:
   1. [95.2%] Nobody:
   2. [88.7%] Me randomly when I love you
   3. [92.3%] Source: @BeamCardShop
   ================================

   Ground truth texts for meme_love_you.jpeg:
     1. Nobody:
     2. Me randomly when I love you
     3. Source: @BeamCardShop
   ```

3. **What to Look For**
   - Number of detected regions matches ground truth
   - Recognized text matches ground truth text
   - Confidence scores (should be >80% for good detection)
   - Any missing or truncated words
   - Any OCR errors or exceptions

#### Testing Multiple Images

By default, only the first image is tested. To cycle through all 10 test images:

1. **Enable Auto-Cycle Feature Flag** (main.dart:14)

   ```dart
   const bool AUTO_CYCLE_TEST_IMAGES = true;  // Change to true
   ```

2. **Run Again**
   - Each image will be tested automatically
   - 10 second interval between images
   - All results logged to console

**Note for AI Agents:** Only enable auto-cycle if user specifically requests testing all images. For routine verification, testing the first image is sufficient.

#### Available Test Images

Located in `example/assets/test_ocr/`:

1. `meme_love_you.jpeg` - Pokemon meme (default)
2. `meme_perfect_couple.jpeg` - Stick figure temperature meme
3. `meme_ice_cream.jpeg` - Ice cream meme
4. `meme_waking_up.jpeg` - Waking up meme
5. `mail_screenshot.jpeg` - Dutch email conversation
6. `ocr_test.jpeg` - Vietnamese restaurant receipt
7. `screen_photos.jpeg` - Dutch FAQ text
8. `text_photos.jpeg` - Dutch poetry on sign
9. `receipt_swiggy.jpg` - Indian food delivery receipt
10. `payment_transactions.png` - Payment app screenshot

Ground truth for all images is in `example/assets/test_ocr/ground_truth.json`.

#### Manual Navigation

- Use arrow buttons (‚Üê ‚Üí) in the app to cycle through test images
- Camera/Gallery buttons to test with custom images
- "Run OCR" button to re-process current image
- Toggle overlay to see detected text boxes visually

## Development Tips

1. **‚ö†Ô∏è CRITICAL: No Large Dependencies**:

   - **NEVER add OpenCV or similar SDKs** - they add 10-20 MB of .so files
   - Only use Android's native APIs: Bitmap, Canvas, Matrix, Paint, etc.
   - Write custom implementations rather than importing large libraries
   - When the Python code uses cv2, find Android equivalents or implement in pure Kotlin
   - Accept minor differences in output vs Python if it means avoiding bloat

2. **Debugging OCR Results**:

   - Enable `save_crop_res` to save cropped text regions
   - Log preprocessing values to verify normalization
   - Check tensor shapes match expected model inputs

3. **Memory Management**:

   - Always dispose of bitmaps after use
   - Close ONNX tensors explicitly
   - Use bitmap.recycle() in Kotlin

4. **Coordinate Systems**:
   - OCR returns coordinates in original image space
   - UI overlay needs transformation to display space
   - Remember to account for BoxFit scaling

## References

- Original Implementation: [OnnxOCR](https://github.com/jingsongliujing/OnnxOCR)
- Models Source: PaddlePaddle's PaddleOCR v5
- ONNX Runtime: [Microsoft ONNX Runtime](https://onnxruntime.ai/)
- OCR Algorithm Papers:
  - DB: [Real-time Scene Text Detection with Differentiable Binarization](https://arxiv.org/abs/1911.08947)
  - SVTR: [Scene Text Recognition with Permuted Autoregressive Sequence Models](https://arxiv.org/abs/2207.06966)

## Session Summary

**Date**: 2025-09-29

**Accomplished**:

- ‚úÖ Created complete Flutter plugin structure
- ‚úÖ Implemented Android native OCR processing
- ‚úÖ Ported all three models (detection, classification, recognition)
- ‚úÖ Created functional sample app with text overlay
- ‚úÖ Fixed overlay positioning issues
- ‚úÖ Added "view all text" feature

**Discovered Issues**:

- ‚ùå Spaces not detected in text
- ‚ùå Word truncation at boundaries
- ‚ùå Memory crashes with large images

**Time Spent**: ~4 hours

**Next Session Priority**: Fix memory issues first (blocking issue), then address text accuracy problems.

---

**Date**: 2025-09-30

**Accomplished**:

- ‚úÖ Fixed space character handling in character dictionary (OcrProcessor.kt)
- ‚úÖ Verified implementation matches Python OnnxOCR source exactly

**Current Issues**:

- üî¥ Word truncation at boundaries (text regions too tight)
- üî¥ Memory crashes with large images (no downscaling)
- üî¥ Index out of bounds errors on certain images

**Next Priority**: Add image size validation and automatic downscaling to prevent OOM crashes.

---

**Date**: 2025-10-01 (Morning Session)

**Test Results - meme_love_you.jpeg** (BEFORE FIXES):

**OCR Output**:

1. [91.5%] Nobody
2. [85.7%] Me randomlv when llove vol
3. [94.8%] Source:@BeamCardShor

**Ground Truth**:

1. Nobody:
2. Me randomly when I love you
3. Source: @BeamCardShop

**Issues Identified**:

- ‚ùå Line 1: Missing colon after "Nobody" (truncation)
- ‚ùå Line 2: Multiple character errors:
  - "randomly" ‚Üí "randomlv" (y‚Üív substitution, confirming tall letter issue)
  - "I love you" ‚Üí "llove vol" (I‚Üíl, u‚Üíl substitutions, truncation)
- ‚ùå Line 3: "BeamCardShop" ‚Üí "BeamCardShor" (p missing, truncation)

**Analysis**:

- Character recognition accuracy: ~85.7% on line 2 (worst case)
- Consistent pattern of truncation at word/sentence boundaries
- Tall letters (y, l, u) frequently misrecognized
- Confirms text region cropping is too tight (insufficient padding)

**Priority**: Fix text region cropping/padding before addressing other issues.

---

**Date**: 2025-10-01 (Afternoon Session)

**Accomplished**:

- ‚úÖ Identified root cause: Missing unclip operation in TextDetector
- ‚úÖ Added polygon expansion logic (unclip operation with 1.5x ratio) to TextDetector.kt
- ‚úÖ Implemented centroid-based polygon expansion algorithm
- ‚úÖ Fixed crop dimension calculation in ImageUtils.kt to use max of opposing sides
- ‚úÖ Tested changes and confirmed significant improvement

**Test Results - meme_love_you.jpeg** (AFTER FIXES):

**OCR Output**:

1. [99.8%] Nobody:
2. [~85%] Me randomly when lve vou
3. [96.6%] Source:@BeamCardShop

**Ground Truth**:

1. Nobody:
2. Me randomly when I love you
3. Source: @BeamCardShop

**Comparison**:
| Text Segment | Before | After | Status |
|--------------|--------|-------|--------|
| "Nobody:" | "Nobody" (truncated) | "Nobody:" | ‚úÖ Perfect |
| "randomly" | "randomlv" | "randomly" | ‚úÖ Fixed |
| "I love you" | "llove vol" | "lve vou" | ‚ö†Ô∏è Improved but errors remain |
| "BeamCardShop" | "BeamCardShor" | "BeamCardShop" | ‚úÖ Perfect |

**Current Issues**:

- ‚ö†Ô∏è "I love you" ‚Üí "lve vou" - character recognition errors persist
  - Missing "I" at start
  - "o" ‚Üí "v" substitution
  - "y" ‚Üí missing
- Still not matching Python implementation quality

**Next Steps**:

1. Compare cropped text regions with Python output (save and inspect actual cropped images)
2. Verify perspective transform parameters match Python exactly:
   - borderMode: cv2.BORDER_REPLICATE
   - interpolation: cv2.INTER_CUBIC
3. Check recognition preprocessing for any subtle differences
4. Goal: Achieve 100% accuracy on "Me randomly when I love you"
